{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/amoghkallihal/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import xmltodict, nltk\n",
    "import json\n",
    "import re, string, ast\n",
    "import numpy as np\n",
    "\n",
    "from nltk import download, tokenize, word_tokenize, pos_tag \n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_click = pd.read_csv('Datasets/clickstream-enwiki-2020-01.tsv', delimiter='\\t', encoding='utf-8', names=['referer', 'resource', 'path', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_click.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('Datasets/enwiki-20200101-pages-articles-multistream-index1.txt-p10p30302', encoding='utf8') as file:\n",
    "#     data_index = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('enwiki-20200101-pages-articles-multistream1.xml-p10p30302', encoding='utf8') as file:\n",
    "    #data_text = file.read()\n",
    "    doc = xmltodict.parse(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print(doc['mediawiki']['page'][11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text = pd.DataFrame(columns=['title', 'text', 'wiki_link', 'redirect'])\n",
    "\n",
    "for page in doc['mediawiki']['page']:\n",
    "    title = page['title']\n",
    "    text_w = ''\n",
    "    text_s = ''\n",
    "    wiki_link = ''\n",
    "    redirect = 'F'\n",
    "    \n",
    "    if 'redirect' in page:\n",
    "        # only keeping redirecting link\n",
    "        txt = re.search('(\\[\\[(.*?)\\]\\])', page['revision']['text']['#text']).group(1)\n",
    "        txt = re.sub('\\[*\\]*', '', txt)\n",
    "        redirect = 'T'\n",
    "        wiki_link = txt.strip()\n",
    "        \n",
    "    else:\n",
    "        # getting rid of {{~}}, [[File:~]], <!-- ~ -->, <ref ~ />, <ref ~</ref>, <br~>\n",
    "        txt = re.sub(r'({{(.*?)}})|(\\[\\[File:(.*?)\\n)|(\\<\\!\\-\\-(.*?)\\-\\-\\>)|(\\<ref(.*?)\\/\\>)|(\\<ref(.*?)\\<\\/ref\\>)|(\\<br(\\s?\\/?)\\>)', \n",
    "                     '', page['revision']['text']['#text'], 0, re.DOTALL)\n",
    "        \n",
    "        # separating internal links\n",
    "        link = re.findall('(\\[\\[(.*?)\\]\\])', txt)\n",
    "        text_w = re.sub('(\\[\\[(.*?)\\]\\])|(\\\\n)', ' ', txt, 0, re.DOTALL)\n",
    "        text_s = re.sub('(?<=^\\[\\[\\b).*(?=\\b\\|(.*?)\\]\\])|(\\\\n)',' ',txt, 0, re.DOTALL) #keeping the links first\n",
    "        text_s = re.sub('(\\[\\[(.*?)\\]\\])|(\\\\n)', ' ', text_s, 0, re.DOTALL)\n",
    "        \n",
    "        for c in link:\n",
    "            if '|' in c[1]:\n",
    "                sep = c[1].split('|')\n",
    "                wiki_link = wiki_link + ', ' + sep[0]\n",
    "                text_w = text_w + ', ' + sep[1]\n",
    "            else:\n",
    "                wiki_link = wiki_link + ', ' + c[1]\n",
    "                text_w = text_w + ', ' + c[1]\n",
    "                \n",
    "    df_text = df_text.append({'title': title, 'text': text_w, 'wiki_link': wiki_link, 'redirect': redirect, 'sentences': text_s}, ignore_index=True) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_text['sentences'][1] # full article text for Anarchism article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(doc):\n",
    "    return tokenize.sent_tokenize(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text['sentences'] = df_text['sentences'].apply(preprocess_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/amoghkallihal/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/amoghkallihal/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_word(doc):\n",
    "    doc = doc.lower()  # Lower the text.\n",
    "    doc = word_tokenize(doc)  # Split into words.\n",
    "    doc = [w for w in doc if not w in stop_words]  # Remove stopwords.\n",
    "    doc = [w for w in doc if w.isalpha()]  # Remove numbers and punctuation.\n",
    "    while (doc.count('n')): \n",
    "        doc.remove('n') \n",
    "    while (doc.count('br')): \n",
    "        doc.remove('br') \n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text['text'] = df_text['text'].apply(preprocess_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_link(doc):\n",
    "    if doc.startswith(', '):\n",
    "        doc = doc[2:]\n",
    "    doc = doc.split(', ')\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text['wiki_link'] = df_text['wiki_link'].apply(preprocess_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Modelling for each topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>wiki_link</th>\n",
       "      <th>redirect</th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AccessibleComputing</td>\n",
       "      <td>[]</td>\n",
       "      <td>Computer accessibility</td>\n",
       "      <td>T</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Anarchism</td>\n",
       "      <td>[rejects, deemed, unjust, advocates, replaceme...</td>\n",
       "      <td>, Anti-authoritarianism, Political philosophy,...</td>\n",
       "      <td>F</td>\n",
       "      <td>[        '''Anarchism''' is an     and   that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AfghanistanHistory</td>\n",
       "      <td>[]</td>\n",
       "      <td>History of Afghanistan</td>\n",
       "      <td>T</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AfghanistanGeography</td>\n",
       "      <td>[]</td>\n",
       "      <td>Geography of Afghanistan</td>\n",
       "      <td>T</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AfghanistanPeople</td>\n",
       "      <td>[]</td>\n",
       "      <td>Demographics of Afghanistan</td>\n",
       "      <td>T</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  title                                               text  \\\n",
       "0   AccessibleComputing                                                 []   \n",
       "1             Anarchism  [rejects, deemed, unjust, advocates, replaceme...   \n",
       "2    AfghanistanHistory                                                 []   \n",
       "3  AfghanistanGeography                                                 []   \n",
       "4     AfghanistanPeople                                                 []   \n",
       "\n",
       "                                           wiki_link redirect  \\\n",
       "0                             Computer accessibility        T   \n",
       "1  , Anti-authoritarianism, Political philosophy,...        F   \n",
       "2                             History of Afghanistan        T   \n",
       "3                           Geography of Afghanistan        T   \n",
       "4                        Demographics of Afghanistan        T   \n",
       "\n",
       "                                           sentences  \n",
       "0                                                 []  \n",
       "1  [        '''Anarchism''' is an     and   that ...  \n",
       "2                                                 []  \n",
       "3                                                 []  \n",
       "4                                                 []  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_words(text):\n",
    "    '''Given a string of text, tokenize the text and pull out only the nouns.'''\n",
    "    is_noun = lambda pos: pos[:2] == 'NN' or pos[:2] == 'JJ' or pos[:2] == 'RB'\n",
    "    tokenized = word_tokenize(text)\n",
    "    all_nouns = [word for (word, pos) in pos_tag(tokenized) if is_noun(pos)] \n",
    "    return ' '.join(all_nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Anarchism unjust replacement societies volunta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19810</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19811</th>\n",
       "      <td>Tax Freedom Day first day year whole theoretic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19812</th>\n",
       "      <td>tax compulsory financial charge other type lev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19813</th>\n",
       "      <td>Transhumanism H h international transformation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19814</th>\n",
       "      <td>episodecreator genre type Travels time space C...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19815 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tokens\n",
       "0                                                       \n",
       "1      Anarchism unjust replacement societies volunta...\n",
       "2                                                       \n",
       "3                                                       \n",
       "4                                                       \n",
       "...                                                  ...\n",
       "19810                                                   \n",
       "19811  Tax Freedom Day first day year whole theoretic...\n",
       "19812  tax compulsory financial charge other type lev...\n",
       "19813  Transhumanism H h international transformation...\n",
       "19814  episodecreator genre type Travels time space C...\n",
       "\n",
       "[19815 rows x 1 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Picks out nouns, adverbs, adjectives and removes unwanted characters of each sentence for each article\n",
    "final_ls = []\n",
    "for i in range(0, len(df_text)):\n",
    "    fil_sent = df_text['sentences'][i]\n",
    "    sen_list = []\n",
    "    for j in range(0,len(fil_sent)):\n",
    "        b = filter_words(fil_sent[j])\n",
    "        res = re.sub('['+string.punctuation+']', '', b).split() \n",
    "        listToStr = ' '.join([str(val) for val in res]) \n",
    "        sen_list.append(listToStr)\n",
    "    listToStr2 = ' '.join([str(val) for val in sen_list])\n",
    "    final_ls.append(listToStr2)\n",
    "new_df = pd.DataFrame({'tokens': final_ls})\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>wiki_link</th>\n",
       "      <th>redirect</th>\n",
       "      <th>sentences</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AccessibleComputing</td>\n",
       "      <td>[]</td>\n",
       "      <td>Computer accessibility</td>\n",
       "      <td>T</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Anarchism</td>\n",
       "      <td>[rejects, deemed, unjust, advocates, replaceme...</td>\n",
       "      <td>, Anti-authoritarianism, Political philosophy,...</td>\n",
       "      <td>F</td>\n",
       "      <td>[        '''Anarchism''' is an     and   that ...</td>\n",
       "      <td>[Anarchism, unjust, replacement, societies, vo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AfghanistanHistory</td>\n",
       "      <td>[]</td>\n",
       "      <td>History of Afghanistan</td>\n",
       "      <td>T</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AfghanistanGeography</td>\n",
       "      <td>[]</td>\n",
       "      <td>Geography of Afghanistan</td>\n",
       "      <td>T</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AfghanistanPeople</td>\n",
       "      <td>[]</td>\n",
       "      <td>Demographics of Afghanistan</td>\n",
       "      <td>T</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19810</th>\n",
       "      <td>The Lord of the Rings/One Ring</td>\n",
       "      <td>[]</td>\n",
       "      <td>One Ring</td>\n",
       "      <td>T</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19811</th>\n",
       "      <td>Tax Freedom Day</td>\n",
       "      <td>[tax, freedom, day, first, day, year, whole, t...</td>\n",
       "      <td>, nation, Tax Foundation, government, Governme...</td>\n",
       "      <td>F</td>\n",
       "      <td>['''Tax Freedom Day''' is the first day of the...</td>\n",
       "      <td>[Tax, Freedom, Day, first, day, year, whole, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19812</th>\n",
       "      <td>Tax</td>\n",
       "      <td>[compulsory, financial, charge, type, levy, im...</td>\n",
       "      <td>, Latin, wikt:en:taxo#Latin, Legal person, tax...</td>\n",
       "      <td>F</td>\n",
       "      <td>[   A '''tax''' (from the   '' '') is a compul...</td>\n",
       "      <td>[tax, compulsory, financial, charge, other, ty...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19813</th>\n",
       "      <td>Transhumanism</td>\n",
       "      <td>[abbreviated, international, advocates, transf...</td>\n",
       "      <td>, school of thought, human condition, human en...</td>\n",
       "      <td>F</td>\n",
       "      <td>[      '''Transhumanism''' (abbreviated as '''...</td>\n",
       "      <td>[Transhumanism, H, h, international, transform...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19814</th>\n",
       "      <td>TARDIS</td>\n",
       "      <td>[genre, type, uses, travels, time, space, trai...</td>\n",
       "      <td>, Anthony Coburn, Science fiction, Time travel...</td>\n",
       "      <td>F</td>\n",
       "      <td>[      | episode_creator =   | genre          ...</td>\n",
       "      <td>[episodecreator, genre, type, Travels, time, s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19815 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                title  \\\n",
       "0                 AccessibleComputing   \n",
       "1                           Anarchism   \n",
       "2                  AfghanistanHistory   \n",
       "3                AfghanistanGeography   \n",
       "4                   AfghanistanPeople   \n",
       "...                               ...   \n",
       "19810  The Lord of the Rings/One Ring   \n",
       "19811                 Tax Freedom Day   \n",
       "19812                             Tax   \n",
       "19813                   Transhumanism   \n",
       "19814                          TARDIS   \n",
       "\n",
       "                                                    text  \\\n",
       "0                                                     []   \n",
       "1      [rejects, deemed, unjust, advocates, replaceme...   \n",
       "2                                                     []   \n",
       "3                                                     []   \n",
       "4                                                     []   \n",
       "...                                                  ...   \n",
       "19810                                                 []   \n",
       "19811  [tax, freedom, day, first, day, year, whole, t...   \n",
       "19812  [compulsory, financial, charge, type, levy, im...   \n",
       "19813  [abbreviated, international, advocates, transf...   \n",
       "19814  [genre, type, uses, travels, time, space, trai...   \n",
       "\n",
       "                                               wiki_link redirect  \\\n",
       "0                                 Computer accessibility        T   \n",
       "1      , Anti-authoritarianism, Political philosophy,...        F   \n",
       "2                                 History of Afghanistan        T   \n",
       "3                               Geography of Afghanistan        T   \n",
       "4                            Demographics of Afghanistan        T   \n",
       "...                                                  ...      ...   \n",
       "19810                                           One Ring        T   \n",
       "19811  , nation, Tax Foundation, government, Governme...        F   \n",
       "19812  , Latin, wikt:en:taxo#Latin, Legal person, tax...        F   \n",
       "19813  , school of thought, human condition, human en...        F   \n",
       "19814  , Anthony Coburn, Science fiction, Time travel...        F   \n",
       "\n",
       "                                               sentences  \\\n",
       "0                                                     []   \n",
       "1      [        '''Anarchism''' is an     and   that ...   \n",
       "2                                                     []   \n",
       "3                                                     []   \n",
       "4                                                     []   \n",
       "...                                                  ...   \n",
       "19810                                                 []   \n",
       "19811  ['''Tax Freedom Day''' is the first day of the...   \n",
       "19812  [   A '''tax''' (from the   '' '') is a compul...   \n",
       "19813  [      '''Transhumanism''' (abbreviated as '''...   \n",
       "19814  [      | episode_creator =   | genre          ...   \n",
       "\n",
       "                                                  tokens  \n",
       "0                                                     []  \n",
       "1      [Anarchism, unjust, replacement, societies, vo...  \n",
       "2                                                     []  \n",
       "3                                                     []  \n",
       "4                                                     []  \n",
       "...                                                  ...  \n",
       "19810                                                 []  \n",
       "19811  [Tax, Freedom, Day, first, day, year, whole, t...  \n",
       "19812  [tax, compulsory, financial, charge, other, ty...  \n",
       "19813  [Transhumanism, H, h, international, transform...  \n",
       "19814  [episodecreator, genre, type, Travels, time, s...  \n",
       "\n",
       "[19815 rows x 6 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text['tokens'] = new_df['tokens'].apply(word_tokenize)\n",
    "df_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nltk_stopwords():\n",
    "    return set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "def prep_corpus(docs, additional_stopwords=set(), no_below=5, no_above=0.5):\n",
    "  print('Building dictionary...')\n",
    "  dictionary = Dictionary(docs)\n",
    "  stopwords = nltk_stopwords().union(additional_stopwords)\n",
    "  stopword_ids = map(dictionary.token2id.get, stopwords)\n",
    "  dictionary.filter_tokens(stopword_ids)\n",
    "  dictionary.compactify()\n",
    "  dictionary.filter_extremes(no_below=no_below, no_above=no_above, keep_n=None)\n",
    "  dictionary.compactify()\n",
    "\n",
    "  print('Building corpus...')\n",
    "  corpus = [dictionary.doc2bow(doc) for doc in docs]\n",
    "\n",
    "  return dictionary, corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building dictionary...\n",
      "Building corpus...\n"
     ]
    }
   ],
   "source": [
    "dictionary, corpus = prep_corpus(df_text['tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "MmCorpus.serialize('wiki_articles.mm', corpus)\n",
    "dictionary.save('wiki_articles.dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 52min 41s, sys: 17.6 s, total: 1h 52min 58s\n",
      "Wall time: 18min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lda = models.ldamodel.LdaModel(corpus=corpus, id2word=dictionary, num_topics=5, passes=100)\n",
    "                                      \n",
    "lda.save('anarchism.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  [('ndash', 0.19607233),\n",
       "   ('American', 0.056985267),\n",
       "   ('b', 0.05306705),\n",
       "   ('player', 0.02313653),\n",
       "   ('politician', 0.020230766),\n",
       "   ('English', 0.020103877),\n",
       "   ('author', 0.013614902),\n",
       "   ('actor', 0.012319651),\n",
       "   ('footballer', 0.01147086),\n",
       "   ('French', 0.009412589)]),\n",
       " (1,\n",
       "  [('code', 0.0047803475),\n",
       "   ('http', 0.0046451846),\n",
       "   ('system', 0.004455545),\n",
       "   ('use', 0.0037908892),\n",
       "   ('first', 0.0036125116),\n",
       "   ('example', 0.0035560185),\n",
       "   ('nbsp', 0.003486357),\n",
       "   ('often', 0.0034348727),\n",
       "   ('time', 0.0033282887),\n",
       "   ('many', 0.0032155628)]),\n",
       " (2,\n",
       "  [('government', 0.0040102643),\n",
       "   ('http', 0.0036458536),\n",
       "   ('nbsp', 0.0033646466),\n",
       "   ('years', 0.0032605599),\n",
       "   ('United', 0.0032056947),\n",
       "   ('country', 0.0030664762),\n",
       "   ('small', 0.0030639376),\n",
       "   ('first', 0.0030424597),\n",
       "   ('–', 0.0029518134),\n",
       "   ('population', 0.002841456)]),\n",
       " (3,\n",
       "  [('style', 0.043180335),\n",
       "   ('math', 0.032911427),\n",
       "   ('right', 0.026713543),\n",
       "   ('textalign', 0.025206244),\n",
       "   ('align', 0.022101833),\n",
       "   ('center', 0.01788409),\n",
       "   ('sup', 0.0125540765),\n",
       "   ('background', 0.012423256),\n",
       "   ('sub', 0.0123471925),\n",
       "   ('nbsp', 0.011852918)]),\n",
       " (4,\n",
       "  [('http', 0.006246395),\n",
       "   ('first', 0.0052187927),\n",
       "   ('https', 0.0040569534),\n",
       "   ('New', 0.0035560173),\n",
       "   ('film', 0.0035520347),\n",
       "   ('Press', 0.0031570008),\n",
       "   ('–', 0.0031542557),\n",
       "   ('time', 0.0030434479),\n",
       "   ('University', 0.003037833),\n",
       "   ('later', 0.002925519)])]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.show_topics(formatted=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
