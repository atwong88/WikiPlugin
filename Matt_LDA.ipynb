{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "Q4NGBdVddtIZ",
    "outputId": "6483dc66-d6ce-4178-8ddb-c34196cbef26"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/matt/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import xmltodict, nltk\n",
    "import json\n",
    "import re, string, ast\n",
    "import numpy as np\n",
    "\n",
    "from gensim import models\n",
    "from gensim.corpora import Dictionary, MmCorpus\n",
    "from nltk import download, tokenize, word_tokenize, pos_tag \n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n7pZt2p5dtJD"
   },
   "outputs": [],
   "source": [
    "with open('enwiki-20200101-pages-articles-multistream1.xml-p10p30302', encoding='utf8') as file:\n",
    "    doc = xmltodict.parse(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CdK4NJKNdtJZ"
   },
   "outputs": [],
   "source": [
    "df_text = pd.DataFrame(columns=['title', 'text', 'wiki_link', 'redirect'])\n",
    "\n",
    "for page in doc['mediawiki']['page']:\n",
    "    title = page['title']\n",
    "    text_w = ''\n",
    "    text_s = ''\n",
    "    wiki_link = ''\n",
    "    redirect = 'F'\n",
    "    \n",
    "    if 'redirect' in page:\n",
    "        # only keeping redirecting link\n",
    "        txt = re.search('(\\[\\[(.*?)\\]\\])', page['revision']['text']['#text']).group(1)\n",
    "        txt = re.sub('\\[*\\]*', '', txt)\n",
    "        redirect = 'T'\n",
    "        wiki_link = txt.strip()\n",
    "        \n",
    "    else:\n",
    "        # getting rid of {{~}}, [[File:~]], <!-- ~ -->, <ref ~ />, <ref ~</ref>, <br~>\n",
    "        txt = re.sub(r'({{(.*?)}})|(\\[\\[File:(.*?)\\n)|(\\<\\!\\-\\-(.*?)\\-\\-\\>)|(\\<ref(.*?)\\/\\>)|(\\<ref(.*?)\\<\\/ref\\>)|(\\<br(\\s?\\/?)\\>)', \n",
    "                     '', page['revision']['text']['#text'], 0, re.DOTALL)\n",
    "        \n",
    "        # separating internal links\n",
    "        link = re.findall('(\\[\\[(.*?)\\]\\])', txt)\n",
    "        text_w = re.sub('(\\[\\[(.*?)\\]\\])|(\\\\n)', ' ', txt, 0, re.DOTALL)\n",
    "        text_s = re.sub('(?<=^\\[\\[\\b).*(?=\\b\\|(.*?)\\]\\])|(\\\\n)',' ',txt, 0, re.DOTALL) #keeping the links first\n",
    "        text_s = re.sub('(\\[\\[(.*?)\\]\\])|(\\\\n)', ' ', text_s, 0, re.DOTALL)\n",
    "        \n",
    "        for c in link:\n",
    "            if '|' in c[1]:\n",
    "                sep = c[1].split('|')\n",
    "                wiki_link = wiki_link + ', ' + sep[0]\n",
    "                text_w = text_w + ', ' + sep[1]\n",
    "            else:\n",
    "                wiki_link = wiki_link + ', ' + c[1]\n",
    "                text_w = text_w + ', ' + c[1]\n",
    "                \n",
    "    df_text = df_text.append({'title': title, 'text': text_w, 'wiki_link': wiki_link, 'redirect': redirect, 'sentences': text_s}, ignore_index=True) \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section that I created the random sampling google sheet. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_text['len'] = df_text['text'].apply(len)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_text = df_text[df_text['len']>0]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "teststr = 'test hello'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "teststr.replace(' ','_')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def linkify(title):\n",
    "    return 'https://en.wikipedia.org/wiki/' + title.replace(' ','_')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_text['link'] = df_text['title'].apply(linkify)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_text_for_sampling = df_text[['title','link']]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_text_for_sampling = df_text_for_sampling.sample(frac=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_text_for_sampling.to_csv('wikipedia_sampling.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text = df_text.head(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ThYkM1k-dtJs"
   },
   "outputs": [],
   "source": [
    "def preprocess_sentence(doc):\n",
    "    return tokenize.sent_tokenize(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DB3RoDxwdtJ5"
   },
   "outputs": [],
   "source": [
    "df_text['sentences'] = df_text['sentences'].apply(preprocess_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "1fFo_6TmdtKF",
    "outputId": "6867f5fd-4a30-4049-9722-9f2456d29e7e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/matt/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/matt/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zGFC_PAHdtKS"
   },
   "outputs": [],
   "source": [
    "def preprocess_word(doc):\n",
    "    doc = doc.lower()  # Lower the text.\n",
    "    doc = word_tokenize(doc)  # Split into words.\n",
    "    doc = [w for w in doc if not w in stop_words]  # Remove stopwords.\n",
    "    doc = [w for w in doc if w.isalpha()]  # Remove numbers and punctuation.\n",
    "    while (doc.count('n')): \n",
    "        doc.remove('n') \n",
    "    while (doc.count('br')): \n",
    "        doc.remove('br') \n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2HQUxR9EdtKa"
   },
   "outputs": [],
   "source": [
    "df_text['text'] = df_text['text'].apply(preprocess_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sDA_7lvBdtKl"
   },
   "outputs": [],
   "source": [
    "def preprocess_link(doc):\n",
    "    if doc.startswith(', '):\n",
    "        doc = doc[2:]\n",
    "    doc = doc.split(', ')\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0F1oX7GDdtKu"
   },
   "outputs": [],
   "source": [
    "df_text['wiki_link'] = df_text['wiki_link'].apply(preprocess_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0YbgIWBEdtK2"
   },
   "source": [
    "# Text Modelling for each topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "colab_type": "code",
    "id": "9Ggs4kZzdtK4",
    "outputId": "d56a0060-b3c1-4886-82a7-a6beb36b77a8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>wiki_link</th>\n",
       "      <th>redirect</th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AccessibleComputing</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Computer accessibility]</td>\n",
       "      <td>T</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Anarchism</td>\n",
       "      <td>[rejects, deemed, unjust, advocates, replaceme...</td>\n",
       "      <td>[Anti-authoritarianism, Political philosophy, ...</td>\n",
       "      <td>F</td>\n",
       "      <td>[        '''Anarchism''' is an     and   that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AfghanistanHistory</td>\n",
       "      <td>[]</td>\n",
       "      <td>[History of Afghanistan]</td>\n",
       "      <td>T</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AfghanistanGeography</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Geography of Afghanistan]</td>\n",
       "      <td>T</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AfghanistanPeople</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Demographics of Afghanistan]</td>\n",
       "      <td>T</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  title                                               text  \\\n",
       "0   AccessibleComputing                                                 []   \n",
       "1             Anarchism  [rejects, deemed, unjust, advocates, replaceme...   \n",
       "2    AfghanistanHistory                                                 []   \n",
       "3  AfghanistanGeography                                                 []   \n",
       "4     AfghanistanPeople                                                 []   \n",
       "\n",
       "                                           wiki_link redirect  \\\n",
       "0                           [Computer accessibility]        T   \n",
       "1  [Anti-authoritarianism, Political philosophy, ...        F   \n",
       "2                           [History of Afghanistan]        T   \n",
       "3                         [Geography of Afghanistan]        T   \n",
       "4                      [Demographics of Afghanistan]        T   \n",
       "\n",
       "                                           sentences  \n",
       "0                                                 []  \n",
       "1  [        '''Anarchism''' is an     and   that ...  \n",
       "2                                                 []  \n",
       "3                                                 []  \n",
       "4                                                 []  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                      []\n",
       "1       [rejects, deemed, unjust, advocates, replaceme...\n",
       "2                                                      []\n",
       "3                                                      []\n",
       "4                                                      []\n",
       "                              ...                        \n",
       "1995    [american, english, term, seven, brightest, st...\n",
       "1996    [settled, nbsp, bc, münir, karaloğlu, city, ea...\n",
       "1997    [capital, billion, gini, hdi, decrease, bs, cc...\n",
       "1998    [united, states, international, date, line, we...\n",
       "1999    [gônoprojatontri, bangladesh, flag, national, ...\n",
       "Name: text, Length: 2000, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WCIFjxxydtK_"
   },
   "outputs": [],
   "source": [
    "def filter_words(text):\n",
    "    '''Given a string of text, tokenize the text and pull out only the nouns.'''\n",
    "    is_noun = lambda pos: pos[:2] == 'NN' or pos[:2] == 'JJ' or pos[:2] == 'RB'\n",
    "    tokenized = word_tokenize(text)\n",
    "    all_nouns = [word for (word, pos) in pos_tag(tokenized) if is_noun(pos)] \n",
    "    return ' '.join(all_nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "colab_type": "code",
    "id": "kpqzLyXOdtLI",
    "outputId": "764bee47-0098-4edc-81e7-cd064a238c01"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Anarchism unjust replacement societies volunta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>American English term brightest stars Plough B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>subdivisiontype subdivisionname subdivisiontyp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>largestcity capital languagestype languages Ot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>archipelago areakm2 areasqmi lengthkm widthkm ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>Gônoprojatontri Bangladesh imageflag Flag Bang...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 tokens\n",
       "0                                                      \n",
       "1     Anarchism unjust replacement societies volunta...\n",
       "2                                                      \n",
       "3                                                      \n",
       "4                                                      \n",
       "...                                                 ...\n",
       "1995  American English term brightest stars Plough B...\n",
       "1996  subdivisiontype subdivisionname subdivisiontyp...\n",
       "1997  largestcity capital languagestype languages Ot...\n",
       "1998  archipelago areakm2 areasqmi lengthkm widthkm ...\n",
       "1999  Gônoprojatontri Bangladesh imageflag Flag Bang...\n",
       "\n",
       "[2000 rows x 1 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Picks out nouns, adverbs, adjectives and removes unwanted characters of each sentence for each article\n",
    "final_ls = []\n",
    "for i in range(0, len(df_text)):\n",
    "    fil_sent = df_text['sentences'][i]\n",
    "    sen_list = []\n",
    "    for j in range(0,len(fil_sent)):\n",
    "        b = filter_words(fil_sent[j])\n",
    "        res = re.sub('['+string.punctuation+']', '', b).split() \n",
    "        listToStr = ' '.join([str(val) for val in res]) \n",
    "        sen_list.append(listToStr)\n",
    "    listToStr2 = ' '.join([str(val) for val in sen_list])\n",
    "    final_ls.append(listToStr2)\n",
    "new_df = pd.DataFrame({'tokens': final_ls})\n",
    "new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matt's territory of LDAvis and topic distribution example with cached LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import string\n",
    "import pandas as pd\n",
    "import sys\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim.models import LdaModel\n",
    "import pyLDAvis.gensim\n",
    "import gensim\n",
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "stopwords = set(stopwords.words('english'))\n",
    "punctuation = set(string.punctuation) \n",
    "lemmatize = WordNetLemmatizer()\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def cleaning(article):\n",
    "    one = \" \".join([i for i in article.lower().split() if i not in stopwords])\n",
    "    two = \"\".join(i for i in oneAndAHalf if i not in punctuation)\n",
    "    three = \" \".join(lemmatize.lemmatize(i) for i in two.split())\n",
    "    return three"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def pre_new(doc):\n",
    "    one = cleaning(doc).split()\n",
    "    two = dictionary.doc2bow(one)\n",
    "    return two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df_text['text'].dropna()\n",
    "text_full = text[text.apply(len)>0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(text_full)\n",
    "doc_term_matrix = [dictionary.doc2bow(doc) for doc in text_full]\n",
    "corpora.MmCorpus.serialize('corpus.mm', doc_term_matrix)\n",
    "Lda = gensim.models.ldamodel.LdaModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldamodel = Lda(doc_term_matrix, num_topics=15, id2word = dictionary, passes=15)\n",
    "c = gensim.corpora.MmCorpus('corpus.mm')\n",
    "ldavisdata = pyLDAvis.gensim.prepare(ldamodel, c, dictionary)\n",
    "pyLDAvis.save_html(ldavisdata,'wiki_topics_15.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now for scoring them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('dictionary.pkl', 'wb')\n",
    "pickle.dump(dictionary, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('ldamodel.pkl', 'wb')\n",
    "pickle.dump(ldamodel, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_term_matrix = [dictionary.doc2bow(doc) for doc in text]\n",
    "corpora.MmCorpus.serialize('corpus.mm', doc_term_matrix)\n",
    "id2word = corpora.Dictionary(text)\n",
    "mm = [id2word.doc2bow(t) for t in text]\n",
    "topics = pd.DataFrame(dict(ldamodel[x]) for x in mm)\n",
    "df_text = df_text.join(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>wiki_link</th>\n",
       "      <th>redirect</th>\n",
       "      <th>sentences</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AccessibleComputing</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Computer accessibility]</td>\n",
       "      <td>T</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Anarchism</td>\n",
       "      <td>[rejects, deemed, unjust, advocates, replaceme...</td>\n",
       "      <td>[Anti-authoritarianism, Political philosophy, ...</td>\n",
       "      <td>F</td>\n",
       "      <td>[        '''Anarchism''' is an     and   that ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.725207</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.269706</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AfghanistanHistory</td>\n",
       "      <td>[]</td>\n",
       "      <td>[History of Afghanistan]</td>\n",
       "      <td>T</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AfghanistanGeography</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Geography of Afghanistan]</td>\n",
       "      <td>T</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AfghanistanPeople</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Demographics of Afghanistan]</td>\n",
       "      <td>T</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  title                                               text  \\\n",
       "0   AccessibleComputing                                                 []   \n",
       "1             Anarchism  [rejects, deemed, unjust, advocates, replaceme...   \n",
       "2    AfghanistanHistory                                                 []   \n",
       "3  AfghanistanGeography                                                 []   \n",
       "4     AfghanistanPeople                                                 []   \n",
       "\n",
       "                                           wiki_link redirect  \\\n",
       "0                           [Computer accessibility]        T   \n",
       "1  [Anti-authoritarianism, Political philosophy, ...        F   \n",
       "2                           [History of Afghanistan]        T   \n",
       "3                         [Geography of Afghanistan]        T   \n",
       "4                      [Demographics of Afghanistan]        T   \n",
       "\n",
       "                                           sentences         0         1  \\\n",
       "0                                                 []  0.066667  0.066667   \n",
       "1  [        '''Anarchism''' is an     and   that ...       NaN  0.725207   \n",
       "2                                                 []  0.066667  0.066667   \n",
       "3                                                 []  0.066667  0.066667   \n",
       "4                                                 []  0.066667  0.066667   \n",
       "\n",
       "          2         3         4         5         6         7         8  \\\n",
       "0  0.066667  0.066667  0.066667  0.066667  0.066667  0.066667  0.066667   \n",
       "1       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "2  0.066667  0.066667  0.066667  0.066667  0.066667  0.066667  0.066667   \n",
       "3  0.066667  0.066667  0.066667  0.066667  0.066667  0.066667  0.066667   \n",
       "4  0.066667  0.066667  0.066667  0.066667  0.066667  0.066667  0.066667   \n",
       "\n",
       "          9        10        11        12        13        14  \n",
       "0  0.066667  0.066667  0.066667  0.066667  0.066667  0.066667  \n",
       "1       NaN  0.269706       NaN       NaN       NaN       NaN  \n",
       "2  0.066667  0.066667  0.066667  0.066667  0.066667  0.066667  \n",
       "3  0.066667  0.066667  0.066667  0.066667  0.066667  0.066667  \n",
       "4  0.066667  0.066667  0.066667  0.066667  0.066667  0.066667  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text.to_csv('LDA_Topics_Sample.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "preprocess+text-modelling.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
